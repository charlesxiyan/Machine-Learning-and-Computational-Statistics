{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d02eb922",
   "metadata": {},
   "source": [
    "### Homework 3\n",
    "##### Charles Yan, xy2985"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe82aba",
   "metadata": {},
   "source": [
    "#### Q1 The classical linear regression model\n",
    "\n",
    "##### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1b9ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "Frobenius Norm of P - P is 4.09e-16\n",
      "=============================================\n",
      "Frobenius Norm of P^2 - P is 6.87e-16\n",
      "=============================================\n",
      "Frobenius Norm of X^T(y - Py) is 3.23e-15\n",
      "=============================================\n",
      "Rank of P is 5.00e+00 v.s. p = 5.\n"
     ]
    }
   ],
   "source": [
    "### (b)\n",
    "import numpy as np\n",
    "np.random.seed(99)\n",
    "\n",
    "n, p = 50, 5\n",
    "X = np.random.normal(0, 1, (n, p))\n",
    "y = np.random.normal(0, 1, (n, 1))\n",
    "P = X @ np.linalg.solve(X.T @ X, X.T)\n",
    "\n",
    "### Tets\n",
    "print('=' * 45)\n",
    "print(f'Frobenius Norm of P - P is {np.linalg.norm(P - P.T):.2e}')\n",
    "print('=' * 45)\n",
    "print(f'Frobenius Norm of P^2 - P is {np.linalg.norm(P @ P - P):.2e}')\n",
    "print('=' * 45)\n",
    "print(f'Frobenius Norm of X^T(y - Py) is {np.linalg.norm(X.T @ (y - P @ y)):.2e}')\n",
    "print('=' * 45)\n",
    "print(f'Rank of P is {np.linalg.matrix_rank(P):.2e} v.s. p = {p}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7f0cd6",
   "metadata": {},
   "source": [
    "##### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315c21d5",
   "metadata": {},
   "source": [
    "##### (d) Proof\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fc1e5d",
   "metadata": {},
   "source": [
    "##### (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b7731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### (f)\n",
    "np.random.seed(99)\n",
    "n, p, B = 200, 3, 500\n",
    "beta = np.array([0.4, 0.5, 0.6])\n",
    "std = 1\n",
    "\n",
    "### (i)\n",
    "X = np.random.normal(0, 1, (n, p))\n",
    "A = np.linalg.inv(X.T @ X)\n",
    "varBetaHat = std ** 2 * A\n",
    "\n",
    "betaHatI = np.zeros((B, p))\n",
    "for b in range(B):\n",
    "    y = X @ beta + np.random.normal(0, 1, n) * std\n",
    "    betaHatI[b] = A @ X.T @ y\n",
    "empVarI = np.cov(betaHatI, rowvar=False)\n",
    "print('=' * 45)\n",
    "print(f'Emp Var - Real Var: {np.linalg.norm(empVarI - varBetaHat):.4e}')\n",
    "print('=' * 45)\n",
    "\n",
    "### (ii)\n",
    "betaHatII = np.zeros((B, p))\n",
    "for b in range(B):\n",
    "    XRand = np.random.normal(0, 1, (n, p))\n",
    "    y = XRand @ beta + np.random.normal(0, 1, n) * std\n",
    "    betaHatII[b] = np.linalg.solve(XRand.T @ XRand, XRand.T @ y)\n",
    "empVarII = np.cov(betaHatII, rowvar=False)\n",
    "print('=' * 45)\n",
    "print(f'Variance of each beta components (i): {np.diag(empVarI)}')\n",
    "print('=' * 45)\n",
    "print(f'Variance of each beta components (ii): {np.diag(empVarII)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa24cacd",
   "metadata": {},
   "source": [
    "##### Q2 Finite-sample properties of OLS\n",
    "\n",
    "##### (a) Assumptions\n",
    "##### (i) Linearity $\\bm{Y} = \\bm{X\\beta} + \\bm{\\epsilon}$.\n",
    "##### (ii) Strict Exogeneity $E[\\bm{\\epsilon\\vert\\bm{X}}] = \\bm{0}$.\n",
    "##### (iii) No Multicolinearity $P(Rank(\\bm{X}) = p) = 1$.\n",
    "##### (iv) Spherical Errors $Var(\\bm{\\epsilon}\\vert\\bm{X}) = \\sigma^{2}\\bm{I}_{n}$.\n",
    "##### (v) Normality $\\bm{\\epsilon}\\vert\\bm{X} \\sim N(\\bm{0}, \\sigma^{2}\\bm{I}_{n})$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a401e96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### (b)\n",
    "np.random.seed(99)\n",
    "n, p, var, B = 80, 5, 2, 5000\n",
    "X = np.random.normal(0, 1, (n, p))\n",
    "beta = np.random.normal(0, 1, p)\n",
    "\n",
    "s2Bias = np.zeros(B)\n",
    "s2Unbias = np.zeros(B)\n",
    "\n",
    "for b in range(B):\n",
    "    eps = np.random.normal(0, np.sqrt(var), n)\n",
    "    y = X @ beta + eps\n",
    "    betaHat = np.linalg.solve(X.T @ X, X.T @ y)\n",
    "    r = y - X @ betaHat\n",
    "    s2Unbias[b] = r @ r / (n - p)\n",
    "    s2Bias[b] = r @ r / n\n",
    "\n",
    "print('=' * 45)\n",
    "print(f'Empirical mean of s2Unbias: {s2Unbias.mean():.4e}, Real Variance: {var:.4e}')\n",
    "print('=' * 45)\n",
    "print(f'Empirical mean of s2Bias: {s2Bias.mean():.4e}, Real Variance: {var:.4e}')\n",
    "print('=' * 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b3ac6",
   "metadata": {},
   "source": [
    "##### As is shown in (a) that $\\dfrac{\\bm{r}^{\\top}\\bm{r}}{n - p}$ is an unbiased estimator of $\\bm{\\sigma}^{2}$. An adjustment on the denominator can make the statistic biased, say $\\dfrac{\\bm{r}^{\\top}\\bm{r}}{n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69f56a0",
   "metadata": {},
   "source": [
    "##### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c27b663",
   "metadata": {},
   "source": [
    "##### (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23811a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### (e)\n",
    "### Note: n, p, var, X, beta are the same as (b)\n",
    "np.random.seed(99)\n",
    "BList = [100, 500, 1000, 5000]\n",
    "\n",
    "for B in BList:\n",
    "    betaHats = np.zeros((B, p))\n",
    "    rs = np.zeros((B, n))\n",
    "\n",
    "    for b in range(B):\n",
    "        eps = np.random.normal(0, np.sqrt(var), n)\n",
    "        y = X @ beta + eps\n",
    "        betaHats[b] = np.linalg.solve(X.T @ X, X.T @ y)\n",
    "        rs[b] = y - X @ betaHats[b]\n",
    "\n",
    "    betaHatMean = betaHats.mean(axis=0)\n",
    "    rMean = rs.mean(axis=0)\n",
    "    CHat = (betaHats - betaHatMean).T @ (rs - rMean) / (B - 1)\n",
    "\n",
    "    print('=' * 45)\n",
    "    print(f'B = {B}: Frobenius Norm of CHat is {np.linalg.norm(CHat):.4e}')\n",
    "    print('=' * 45)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179a9199",
   "metadata": {},
   "source": [
    "##### As shown above in the numerical outcome, the Frobenius norm of $\\hat{\\bm{C}}$ is shrinking as B goes larger."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f624759",
   "metadata": {},
   "source": [
    "##### Q3 Hypothesis Testing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLCS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
